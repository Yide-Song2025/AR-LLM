{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12282,"status":"ok","timestamp":1765515781891,"user":{"displayName":"Scott Zhou","userId":"17529720457164178193"},"user_tz":300},"id":"leYyhUVTrvAN","outputId":"e9499b49-d05c-44d8-abc1-59c74d5747d9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/Files/COMP545_PROJECT\n"]}],"source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd /content/drive/MyDrive/Files/COMP545_PROJECT"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"YL2-ODGDrYYn","executionInfo":{"status":"ok","timestamp":1765515782673,"user_tz":300,"elapsed":780,"user":{"displayName":"Scott Zhou","userId":"17529720457164178193"}}},"outputs":[],"source":["import huggingface_hub\n","huggingface_hub.login(\"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\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_NKqKRuUsOKI","outputId":"b5bd6e85-9b9c-4e20-e247-ec0ea12a8e70","executionInfo":{"status":"ok","timestamp":1764986294641,"user_tz":300,"elapsed":18927754,"user":{"displayName":"Scott Zhou","userId":"17529720457164178193"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","Loading tokenizer...\n","tokenizer_config.json: 100% 1.16M/1.16M [00:00<00:00, 5.44MB/s]\n","tokenizer.model: 100% 4.69M/4.69M [00:01<00:00, 3.68MB/s]\n","tokenizer.json: 100% 33.4M/33.4M [00:00<00:00, 64.9MB/s]\n","added_tokens.json: 100% 35.0/35.0 [00:00<00:00, 254kB/s]\n","special_tokens_map.json: 100% 662/662 [00:00<00:00, 4.08MB/s]\n","Loading data...\n","Loading query difficulty data from: data/model_data/query_difficulty.jsonl\n","Loaded 18705 queries with difficulty scores\n","Sample data: {'query_id': 'bbh_q635', 'dataset': 'bbh', 'subset': 'date_understanding', 'query': 'Jane quited her job on Mar 20, 2020. 176 days have passed since then. What is the date yesterday in MM/DD/YYYY?\\nOptions:\\n(A) 09/11/2094\\n(B) 09/11/2020\\n(C) 09/10/2020\\n(D) 08/14/2020\\n(E) 10/09/2020\\n(F) 09/17/2020', 'difficulty': 100.0, 'wrong_answers': 16, 'unique_models': 16, 'total_answers': 16, 'correct_answers': 0}\n","Train samples: 18705, Test samples: 936\n","Creating datasets...\n","Using difficulty prediction with soft labels (0-1 normalized from difficulty scores).\n","Creating model...\n","config.json: 100% 1.49k/1.49k [00:00<00:00, 13.7MB/s]\n","2025-12-05 20:43:13.109009: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2025-12-05 20:43:13.129535: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1764967393.155676    1684 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1764967393.163900    1684 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","W0000 00:00:1764967393.183445    1684 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1764967393.183468    1684 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1764967393.183472    1684 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1764967393.183474    1684 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","2025-12-05 20:43:13.187635: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","model.safetensors: 100% 1.21G/1.21G [00:02<00:00, 471MB/s]\n","Model parameters: 304.05M\n","\n","Starting training from scratch...\n","Batch size: 4, Gradient accumulation steps: 4\n","Effective batch size: 16\n","Epoch 1/10:  11% 499/4677 [13:26<1:51:12,  1.60s/it, loss=0.6593]Saved checkpoint to Temp/embeddinggemma_difficulty_predictor/latest_checkpoint.pth\n","                                                                 \n","Saved checkpoint and model to Temp/embeddinggemma_difficulty_predictor\n","Epoch 1/10:  21% 999/4677 [27:07<1:37:47,  1.60s/it, loss=0.7304]Saved checkpoint to Temp/embeddinggemma_difficulty_predictor/latest_checkpoint.pth\n","                                                                 \n","Saved checkpoint and model to Temp/embeddinggemma_difficulty_predictor\n","Epoch 1/10:  32% 1499/4677 [40:49<1:24:19,  1.59s/it, loss=0.6933]Saved checkpoint to Temp/embeddinggemma_difficulty_predictor/latest_checkpoint.pth\n","                                                                  \n","Saved checkpoint and model to Temp/embeddinggemma_difficulty_predictor\n","Removed old model weights: Temp/embeddinggemma_difficulty_predictor/model_epoch_0_batch_500.pth\n","Epoch 1/10:  43% 1999/4677 [54:26<1:11:15,  1.60s/it, loss=0.5633]Saved checkpoint to Temp/embeddinggemma_difficulty_predictor/latest_checkpoint.pth\n","                                                                  \n","Saved checkpoint and model to Temp/embeddinggemma_difficulty_predictor\n","Removed old model weights: Temp/embeddinggemma_difficulty_predictor/model_epoch_0_batch_1000.pth\n","Epoch 1/10:  53% 2499/4677 [1:08:05<57:47,  1.59s/it, loss=0.6808]Saved checkpoint to Temp/embeddinggemma_difficulty_predictor/latest_checkpoint.pth\n","                                                                  \n","Saved checkpoint and model to Temp/embeddinggemma_difficulty_predictor\n","Removed old model weights: Temp/embeddinggemma_difficulty_predictor/model_epoch_0_batch_1500.pth\n","Epoch 1/10:  64% 2999/4677 [1:21:40<44:38,  1.60s/it, loss=0.6495]Saved checkpoint to Temp/embeddinggemma_difficulty_predictor/latest_checkpoint.pth\n","                                                                  \n","Saved checkpoint and model to Temp/embeddinggemma_difficulty_predictor\n","Removed old model weights: Temp/embeddinggemma_difficulty_predictor/model_epoch_0_batch_2000.pth\n","Epoch 1/10:  75% 3499/4677 [1:35:19<31:14,  1.59s/it, loss=0.6576]Saved checkpoint to Temp/embeddinggemma_difficulty_predictor/latest_checkpoint.pth\n","                                                                  \n","Saved checkpoint and model to Temp/embeddinggemma_difficulty_predictor\n","Removed old model weights: Temp/embeddinggemma_difficulty_predictor/model_epoch_0_batch_2500.pth\n","Epoch 1/10:  86% 3999/4677 [1:48:58<18:02,  1.60s/it, loss=0.7007]Saved checkpoint to Temp/embeddinggemma_difficulty_predictor/latest_checkpoint.pth\n","                                                                  \n","Saved checkpoint and model to Temp/embeddinggemma_difficulty_predictor\n","Removed old model weights: Temp/embeddinggemma_difficulty_predictor/model_epoch_0_batch_3000.pth\n","Epoch 1/10:  96% 4499/4677 [2:02:36<04:43,  1.59s/it, loss=0.6674]Saved checkpoint to Temp/embeddinggemma_difficulty_predictor/latest_checkpoint.pth\n","                                                                  \n","Saved checkpoint and model to Temp/embeddinggemma_difficulty_predictor\n","Removed old model weights: Temp/embeddinggemma_difficulty_predictor/model_epoch_0_batch_3500.pth\n","Epoch 1/10: 100% 4677/4677 [2:07:34<00:00,  1.64s/it, loss=0.4160]\n","\n","Epoch 1/10 - Train Loss: 0.6580, Test Loss: 0.6404, Test Acc: 0.7500, Best Test Acc: -1.0000\n","Saved checkpoint to Temp/embeddinggemma_difficulty_predictor/latest_checkpoint.pth\n","\n","Saved best model to Temp/embeddinggemma_difficulty_predictor/model_loss_0.6580_acc_0.7500_epoch_0.pth\n","Epoch 2/10:  11% 499/4677 [13:23<1:50:51,  1.59s/it, loss=0.7280]Saved checkpoint to Temp/embeddinggemma_difficulty_predictor/latest_checkpoint.pth\n","                                                                 \n","Saved checkpoint and model to Temp/embeddinggemma_difficulty_predictor\n","Removed old model weights: Temp/embeddinggemma_difficulty_predictor/model_epoch_0_batch_4000.pth\n","Epoch 2/10:  21% 999/4677 [27:03<1:37:55,  1.60s/it, loss=0.5393]Saved checkpoint to Temp/embeddinggemma_difficulty_predictor/latest_checkpoint.pth\n","                                                                 \n","Saved checkpoint and model to Temp/embeddinggemma_difficulty_predictor\n","Removed old model weights: Temp/embeddinggemma_difficulty_predictor/model_epoch_0_batch_4500.pth\n","Epoch 2/10:  32% 1499/4677 [40:40<1:24:15,  1.59s/it, loss=0.8567]Saved checkpoint to Temp/embeddinggemma_difficulty_predictor/latest_checkpoint.pth\n","                                                                  \n","Saved checkpoint and model to Temp/embeddinggemma_difficulty_predictor\n","Removed old model weights: Temp/embeddinggemma_difficulty_predictor/model_epoch_1_batch_500.pth\n","Epoch 2/10:  43% 1999/4677 [54:19<1:11:20,  1.60s/it, loss=0.7862]Saved checkpoint to Temp/embeddinggemma_difficulty_predictor/latest_checkpoint.pth\n","                                                                  \n","Saved checkpoint and model to Temp/embeddinggemma_difficulty_predictor\n","Removed old model weights: Temp/embeddinggemma_difficulty_predictor/model_epoch_1_batch_1000.pth\n","Epoch 2/10:  53% 2499/4677 [1:08:00<57:57,  1.60s/it, loss=0.6260]Saved checkpoint to Temp/embeddinggemma_difficulty_predictor/latest_checkpoint.pth\n","                                                                  \n","Saved checkpoint and model to Temp/embeddinggemma_difficulty_predictor\n","Removed old model weights: Temp/embeddinggemma_difficulty_predictor/model_epoch_1_batch_1500.pth\n","Epoch 2/10:  64% 2999/4677 [1:21:37<44:32,  1.59s/it, loss=0.7029]Saved checkpoint to Temp/embeddinggemma_difficulty_predictor/latest_checkpoint.pth\n","                                                                  \n","Saved checkpoint and model to Temp/embeddinggemma_difficulty_predictor\n","Removed old model weights: Temp/embeddinggemma_difficulty_predictor/model_epoch_1_batch_2000.pth\n","Epoch 2/10:  75% 3499/4677 [1:35:15<31:22,  1.60s/it, loss=0.6108]Saved checkpoint to Temp/embeddinggemma_difficulty_predictor/latest_checkpoint.pth\n","                                                                  \n","Saved checkpoint and model to Temp/embeddinggemma_difficulty_predictor\n","Removed old model weights: Temp/embeddinggemma_difficulty_predictor/model_epoch_1_batch_2500.pth\n","Epoch 2/10:  86% 3999/4677 [1:48:54<17:58,  1.59s/it, loss=0.5958]Saved checkpoint to Temp/embeddinggemma_difficulty_predictor/latest_checkpoint.pth\n","                                                                  \n","Saved checkpoint and model to Temp/embeddinggemma_difficulty_predictor\n","Removed old model weights: Temp/embeddinggemma_difficulty_predictor/model_epoch_1_batch_3000.pth\n","Epoch 2/10:  96% 4499/4677 [2:02:30<04:43,  1.59s/it, loss=0.6630]Saved checkpoint to Temp/embeddinggemma_difficulty_predictor/latest_checkpoint.pth\n","                                                                  \n","Saved checkpoint and model to Temp/embeddinggemma_difficulty_predictor\n","Removed old model weights: Temp/embeddinggemma_difficulty_predictor/model_epoch_1_batch_3500.pth\n","Epoch 2/10: 100% 4677/4677 [2:07:35<00:00,  1.64s/it, loss=0.8010]\n","\n","Epoch 2/10 - Train Loss: 0.6388, Test Loss: 0.6198, Test Acc: 0.5737, Best Test Acc: 0.7500\n","Saved checkpoint to Temp/embeddinggemma_difficulty_predictor/latest_checkpoint.pth\n","\n","Saved best model to Temp/embeddinggemma_difficulty_predictor/model_loss_0.6388_acc_0.5737_epoch_1.pth\n","Epoch 3/10:  11% 499/4677 [13:23<1:50:58,  1.59s/it, loss=0.7676]Saved checkpoint to Temp/embeddinggemma_difficulty_predictor/latest_checkpoint.pth\n","                                                                 \n","Saved checkpoint and model to Temp/embeddinggemma_difficulty_predictor\n","Removed old model weights: Temp/embeddinggemma_difficulty_predictor/model_epoch_1_batch_4000.pth\n","Epoch 3/10:  21% 999/4677 [27:00<1:37:35,  1.59s/it, loss=0.6818]Saved checkpoint to Temp/embeddinggemma_difficulty_predictor/latest_checkpoint.pth\n","                                                                 \n","Saved checkpoint and model to Temp/embeddinggemma_difficulty_predictor\n","Removed old model weights: Temp/embeddinggemma_difficulty_predictor/model_epoch_1_batch_4500.pth\n","Epoch 3/10:  32% 1499/4677 [40:37<1:24:16,  1.59s/it, loss=0.5244]Saved checkpoint to Temp/embeddinggemma_difficulty_predictor/latest_checkpoint.pth\n","                                                                  \n","Saved checkpoint and model to Temp/embeddinggemma_difficulty_predictor\n","Removed old model weights: Temp/embeddinggemma_difficulty_predictor/model_epoch_2_batch_500.pth\n","Epoch 3/10:  43% 1999/4677 [54:18<1:11:17,  1.60s/it, loss=0.6288]Saved checkpoint to Temp/embeddinggemma_difficulty_predictor/latest_checkpoint.pth\n","                                                                  \n","Saved checkpoint and model to Temp/embeddinggemma_difficulty_predictor\n","Removed old model weights: Temp/embeddinggemma_difficulty_predictor/model_epoch_2_batch_1000.pth\n","Epoch 3/10:  43% 2024/4677 [55:12<1:12:21,  1.64s/it, loss=0.6951]\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/Files/COMP545_PROJECT/train.py\", line 190, in <module>\n","^C\n"]}],"source":["!python train.py \\\n","--save_steps 500 \\\n","--max_checkpoints 2 \\\n","--num_epochs 10 \\\n","--batch_size 4 \\\n","--gradient_accumulation_steps 4 \\\n","--save_path Temp\n","# --resume_from_checkpoint model_checkpoints/embeddinggemma_binary_classifier/latest_checkpoint.pth"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":407258,"status":"ok","timestamp":1764991862023,"user":{"displayName":"Scott Zhou","userId":"17529720457164178193"},"user_tz":300},"id":"5dScgmhLS9mt","outputId":"966c8b6b-9be3-46ea-e4f9-7931abe2501d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading data from data/model_data/extracted_dataset_samples_ood.jsonl...\n","Found 1301 unique queries\n","Datasets: {'gpqa': 545, 'musr': 756}\n","tokenizer_config.json: 100% 1.16M/1.16M [00:00<00:00, 1.38MB/s]\n","tokenizer.model: 100% 4.69M/4.69M [00:01<00:00, 3.62MB/s]\n","tokenizer.json: 100% 33.4M/33.4M [00:00<00:00, 65.1MB/s]\n","added_tokens.json: 100% 35.0/35.0 [00:00<00:00, 307kB/s]\n","special_tokens_map.json: 100% 662/662 [00:00<00:00, 4.97MB/s]\n","\n","Loading multi-class model from model_checkpoints/embeddinggemma_multi_class_classifier/best_model_acc_0.9849_epoch_1.pth...\n","config.json: 100% 1.49k/1.49k [00:00<00:00, 13.4MB/s]\n","2025-12-06 03:24:31.838333: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2025-12-06 03:24:31.858922: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1764991471.885423    1809 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1764991471.893691    1809 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","W0000 00:00:1764991471.913839    1809 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1764991471.913873    1809 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1764991471.913876    1809 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1764991471.913879    1809 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","2025-12-06 03:24:31.918999: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","model.safetensors: 100% 1.21G/1.21G [00:02<00:00, 556MB/s]\n","Multi-class model loaded successfully\n","\n","Loading binary model from model_checkpoints/embeddinggemma_difficulty_predictor/final_model.pth...\n","Binary model loaded successfully\n","\n","Performing inference...\n","Predicting: 100% 41/41 [05:41<00:00,  8.34s/it]\n","\n","Saving results to data/feature_vectors/extracted_dataset_samples_ood_features.jsonl...\n","Successfully saved 1301 predictions\n","Feature vector dimension: 4\n"]}],"source":["!python predict_feature_vectors.py \\\n","--binary_model model_checkpoints/embeddinggemma_difficulty_predictor/final_model.pth \\\n","--input_file data/model_data/extracted_dataset_samples_ood.jsonl"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tuBaOoVhEOqx","executionInfo":{"status":"ok","timestamp":1764990720312,"user_tz":300,"elapsed":142069,"user":{"displayName":"Scott Zhou","userId":"17529720457164178193"}},"outputId":"7165299d-4ea2-412c-83e7-a62fc8d5c5ce"},"outputs":[{"output_type":"stream","name":"stdout","text":["Target models: 16\n","  - MaziyarPanahi/calme-3.2-instruct-78b\n","  - Qwen/Qwen2.5-32B-Instruct\n","  - Qwen/Qwen2.5-72B-Instruct\n","  - Qwen/Qwen2.5-14B-Instruct\n","  - Qwen/Qwen2.5-7B-Instruct\n","  - Qwen/Qwen2.5-3B-Instruct\n","  - Qwen/Qwen2.5-1.5B-Instruct\n","  - Qwen/Qwen2.5-0.5B-Instruct\n","  - meta-llama/Llama-3.1-70B-Instruct\n","  - meta-llama/Llama-3.1-8B-Instruct\n","  - meta-llama/Llama-3.3-70B-Instruct\n","  - meta-llama/Llama-3.2-3B-Instruct\n","  - meta-llama/Llama-3.2-1B-Instruct\n","  - deepseek-ai/DeepSeek-R1-Distill-Qwen-14B\n","  - deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\n","  - deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\n","\n","Target datasets:\n","  - BBH (24 subsets)\n","  - MATH (7 subsets)\n","  - MMLU-Pro\n","\n","================================================================================\n","Processing model: MaziyarPanahi/calme-3.2-instruct-78b\n","================================================================================\n","  GPQA-Main : Success\n","  GPQA-Diamond : Success\n","  GPQA-Extended : Success\n","  MUSR-Murder-Mysteries : Success\n","(…)cements_2024-12-03T18-16-48.043062.jsonl: 100% 6.41M/6.41M [00:00<00:00, 34.1MB/s]\n","Generating 2024_12_03T18_16_48.043062 split: 100% 256/256 [00:00<00:00, 4184.64 examples/s]\n","Generating latest split: 100% 256/256 [00:00<00:00, 3713.69 examples/s]\n","  MUSR-Object-Placement : Success\n","  MUSR-Team-Allocation : Success\n","\n","================================================================================\n","Processing model: Qwen/Qwen2.5-32B-Instruct\n","================================================================================\n","  GPQA-Main : Success\n","  GPQA-Diamond : Success\n","  GPQA-Extended : Success\n","  MUSR-Murder-Mysteries : Success\n","(…)cements_2024-09-19T12-58-54.557932.jsonl: 100% 6.50M/6.50M [00:00<00:00, 25.0MB/s]\n","Generating 2024_09_19T12_58_54.557932 split: 100% 256/256 [00:00<00:00, 4147.59 examples/s]\n","Generating latest split: 100% 256/256 [00:00<00:00, 4301.83 examples/s]\n","  MUSR-Object-Placement : Success\n","  MUSR-Team-Allocation : Success\n","\n","================================================================================\n","Processing model: Qwen/Qwen2.5-72B-Instruct\n","================================================================================\n","  GPQA-Main : Success\n","  GPQA-Diamond : Success\n","  GPQA-Extended : Success\n","  MUSR-Murder-Mysteries : Success\n","(…)cements_2024-10-17T09-04-04.637164.jsonl: 100% 6.50M/6.50M [00:00<00:00, 40.2MB/s]\n","Generating 2024_10_17T09_04_04.637164 split: 100% 256/256 [00:00<00:00, 3869.76 examples/s]\n","Generating latest split: 100% 256/256 [00:00<00:00, 5017.98 examples/s]\n","  MUSR-Object-Placement : Success\n","  MUSR-Team-Allocation : Success\n","\n","================================================================================\n","Processing model: Qwen/Qwen2.5-14B-Instruct\n","================================================================================\n","  GPQA-Main : Success\n","  GPQA-Diamond : Success\n","  GPQA-Extended : Success\n","  MUSR-Murder-Mysteries : Success\n","(…)cements_2024-09-19T08-51-03.564190.jsonl: 100% 6.50M/6.50M [00:00<00:00, 22.8MB/s]\n","Generating 2024_09_19T08_51_03.564190 split: 100% 256/256 [00:00<00:00, 4050.76 examples/s]\n","Generating latest split: 100% 256/256 [00:00<00:00, 3391.63 examples/s]\n","  MUSR-Object-Placement : Success\n","  MUSR-Team-Allocation : Success\n","\n","================================================================================\n","Processing model: Qwen/Qwen2.5-7B-Instruct\n","================================================================================\n","  GPQA-Main : Success\n","  GPQA-Diamond : Success\n","  GPQA-Extended : Success\n","  MUSR-Murder-Mysteries : Success\n","(…)cements_2024-09-19T16-21-01.446061.jsonl: 100% 6.50M/6.50M [00:00<00:00, 26.5MB/s]\n","Generating 2024_09_19T16_21_01.446061 split: 100% 256/256 [00:00<00:00, 5602.79 examples/s]\n","Generating latest split: 100% 256/256 [00:00<00:00, 5876.30 examples/s]\n","  MUSR-Object-Placement : Success\n","  MUSR-Team-Allocation : Success\n","\n","================================================================================\n","Processing model: Qwen/Qwen2.5-3B-Instruct\n","================================================================================\n","  GPQA-Main : Success\n","  GPQA-Diamond : Success\n","  GPQA-Extended : Success\n","  MUSR-Murder-Mysteries : Success\n","(…)cements_2024-09-19T10-05-30.339220.jsonl: 100% 6.50M/6.50M [00:00<00:00, 38.4MB/s]\n","Generating 2024_09_19T10_05_30.339220 split: 100% 256/256 [00:00<00:00, 5126.43 examples/s]\n","Generating latest split: 100% 256/256 [00:00<00:00, 3124.47 examples/s]\n","  MUSR-Object-Placement : Success\n","  MUSR-Team-Allocation : Success\n","\n","================================================================================\n","Processing model: Qwen/Qwen2.5-1.5B-Instruct\n","================================================================================\n","'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: f3d5cd1b-d55d-43eb-b2de-745939ed8401)')' thrown while requesting HEAD https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen2.5-1.5B-Instruct-details/resolve/801e825efda393dafd601fc9f9fa85646050f3b5/Qwen__Qwen2.5-1.5B-Instruct-details.py\n","Retrying in 1s [Retry 1/5].\n","  GPQA-Main : Success\n","  GPQA-Diamond : Success\n","  GPQA-Extended : Success\n","  MUSR-Murder-Mysteries : Success\n","(…)cements_2024-09-19T16-22-58.240552.jsonl: 100% 6.50M/6.50M [00:00<00:00, 35.0MB/s]\n","Generating 2024_09_19T16_22_58.240552 split: 100% 256/256 [00:00<00:00, 5533.72 examples/s]\n","Generating latest split: 100% 256/256 [00:00<00:00, 5704.93 examples/s]\n","  MUSR-Object-Placement : Success\n","  MUSR-Team-Allocation : Success\n","\n","================================================================================\n","Processing model: Qwen/Qwen2.5-0.5B-Instruct\n","================================================================================\n","  GPQA-Main : Success\n","  GPQA-Diamond : Success\n","  GPQA-Extended : Success\n","  MUSR-Murder-Mysteries : Success\n","(…)cements_2024-10-16T10-12-57.756697.jsonl: 100% 6.51M/6.51M [00:00<00:00, 20.0MB/s]\n","Generating 2024_10_16T10_12_57.756697 split: 100% 256/256 [00:00<00:00, 5302.87 examples/s]\n","Generating latest split: 100% 256/256 [00:00<00:00, 4142.76 examples/s]\n","  MUSR-Object-Placement : Success\n","  MUSR-Team-Allocation : Success\n","\n","================================================================================\n","Processing model: meta-llama/Llama-3.1-70B-Instruct\n","================================================================================\n","  GPQA-Main : Success\n","  GPQA-Diamond : Success\n","  GPQA-Extended : Success\n","  MUSR-Murder-Mysteries : Success\n","meta-llama__Llama-3.1-70B-Instruct/sampl(…): 100% 6.47M/6.47M [00:00<00:00, 7.37MB/s]\n","Generating 2024_07_19T18_47_29.522341 split: 100% 256/256 [00:00<00:00, 3103.38 examples/s]\n","Generating latest split: 100% 256/256 [00:00<00:00, 4335.71 examples/s]\n","  MUSR-Object-Placement : Success\n","  MUSR-Team-Allocation : Success\n","\n","================================================================================\n","Processing model: meta-llama/Llama-3.1-8B-Instruct\n","================================================================================\n","  GPQA-Main : Success\n","  GPQA-Diamond : Success\n","  GPQA-Extended : Success\n","  MUSR-Murder-Mysteries : Success\n","(…)cements_2025-02-06T09-50-12.953027.jsonl: 100% 6.36M/6.36M [00:00<00:00, 30.3MB/s]\n","Generating 2025_02_06T09_50_12.953027 split: 100% 256/256 [00:00<00:00, 4519.46 examples/s]\n","Generating latest split: 100% 256/256 [00:00<00:00, 5384.11 examples/s]\n","  MUSR-Object-Placement : Success\n","  MUSR-Team-Allocation : Success\n","\n","================================================================================\n","Processing model: meta-llama/Llama-3.3-70B-Instruct\n","================================================================================\n","  GPQA-Main : Success\n","  GPQA-Diamond : Success\n","  GPQA-Extended : Success\n","  MUSR-Murder-Mysteries : Success\n","(…)cements_2024-12-04T14-39-18.066641.jsonl: 100% 6.58M/6.58M [00:00<00:00, 32.4MB/s]\n","Generating 2024_12_04T14_39_18.066641 split: 100% 256/256 [00:00<00:00, 4074.13 examples/s]\n","Generating latest split: 100% 256/256 [00:00<00:00, 5041.30 examples/s]\n","  MUSR-Object-Placement : Success\n","  MUSR-Team-Allocation : Success\n","\n","================================================================================\n","Processing model: meta-llama/Llama-3.2-3B-Instruct\n","================================================================================\n","  GPQA-Main : Success\n","  GPQA-Diamond : Success\n","  GPQA-Extended : Success\n","  MUSR-Murder-Mysteries : Success\n","meta-llama__Llama-3.2-3B-Instruct/sample(…): 100% 6.59M/6.59M [00:00<00:00, 8.24MB/s]\n","Generating 2024_09_27T08_39_46.273084 split: 100% 256/256 [00:00<00:00, 4803.68 examples/s]\n","Generating latest split: 100% 256/256 [00:00<00:00, 3739.49 examples/s]\n","  MUSR-Object-Placement : Success\n","  MUSR-Team-Allocation : Success\n","\n","================================================================================\n","Processing model: meta-llama/Llama-3.2-1B-Instruct\n","================================================================================\n","  GPQA-Main : Success\n","  GPQA-Diamond : Success\n","  GPQA-Extended : Success\n","  MUSR-Murder-Mysteries : Success\n","meta-llama__Llama-3.2-1B-Instruct/sample(…): 100% 6.47M/6.47M [00:00<00:00, 13.6MB/s]\n","Generating 2024_09_23T09_44_39.710857 split: 100% 256/256 [00:00<00:00, 2767.85 examples/s]\n","Generating latest split: 100% 256/256 [00:00<00:00, 2859.93 examples/s]\n","  MUSR-Object-Placement : Success\n","  MUSR-Team-Allocation : Success\n","\n","================================================================================\n","Processing model: deepseek-ai/DeepSeek-R1-Distill-Qwen-14B\n","================================================================================\n","  GPQA-Main : Success\n","  GPQA-Diamond : Success\n","  GPQA-Extended : Success\n","  MUSR-Murder-Mysteries : Success\n","(…)cements_2025-01-20T19-24-00.236504.jsonl: 100% 6.36M/6.36M [00:00<00:00, 42.8MB/s]\n","Generating 2025_01_20T19_24_00.236504 split: 100% 256/256 [00:00<00:00, 4969.60 examples/s]\n","Generating latest split: 100% 256/256 [00:00<00:00, 3302.27 examples/s]\n","  MUSR-Object-Placement : Success\n","  MUSR-Team-Allocation : Success\n","\n","================================================================================\n","Processing model: deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\n","================================================================================\n","  GPQA-Main : Success\n","  GPQA-Diamond : Success\n","  GPQA-Extended : Success\n","  MUSR-Murder-Mysteries : Success\n","(…)cements_2025-01-22T01-33-03.348162.jsonl: 100% 6.41M/6.41M [00:00<00:00, 24.4MB/s]\n","Generating 2025_01_22T01_33_03.348162 split: 100% 256/256 [00:00<00:00, 3246.89 examples/s]\n","Generating latest split: 100% 256/256 [00:00<00:00, 3192.85 examples/s]\n","  MUSR-Object-Placement : Success\n","  MUSR-Team-Allocation : Success\n","\n","================================================================================\n","Processing model: deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\n","================================================================================\n","  GPQA-Main : Success\n","  GPQA-Diamond : Success\n","  GPQA-Extended : Success\n","  MUSR-Murder-Mysteries : Success\n","(…)cements_2025-01-20T22-51-25.465135.jsonl: 100% 6.41M/6.41M [00:00<00:00, 31.6MB/s]\n","Generating 2025_01_20T22_51_25.465135 split: 100% 256/256 [00:00<00:00, 4376.89 examples/s]\n","Generating latest split: 100% 256/256 [00:00<00:00, 4241.00 examples/s]\n","  MUSR-Object-Placement : Success\n","  MUSR-Team-Allocation : Success\n","\n","Extraction completed!\n","Total records extracted: 31168\n","Saved to: data/model_data/openllm_leaderboard_extracted_data_ood.jsonl\n","\n","Data statistics:\n","\n","By model:\n","  MaziyarPanahi/calme-3.2-instruct-78b: 1948 records\n","  Qwen/Qwen2.5-32B-Instruct: 1948 records\n","  Qwen/Qwen2.5-72B-Instruct: 1948 records\n","  Qwen/Qwen2.5-14B-Instruct: 1948 records\n","  Qwen/Qwen2.5-7B-Instruct: 1948 records\n","  Qwen/Qwen2.5-3B-Instruct: 1948 records\n","  Qwen/Qwen2.5-1.5B-Instruct: 1948 records\n","  Qwen/Qwen2.5-0.5B-Instruct: 1948 records\n","  meta-llama/Llama-3.1-70B-Instruct: 1948 records\n","  meta-llama/Llama-3.1-8B-Instruct: 1948 records\n","  meta-llama/Llama-3.3-70B-Instruct: 1948 records\n","  meta-llama/Llama-3.2-3B-Instruct: 1948 records\n","  meta-llama/Llama-3.2-1B-Instruct: 1948 records\n","  deepseek-ai/DeepSeek-R1-Distill-Qwen-14B: 1948 records\n","  deepseek-ai/DeepSeek-R1-Distill-Qwen-32B: 1948 records\n","  deepseek-ai/DeepSeek-R1-Distill-Qwen-7B: 1948 records\n","\n","By dataset:\n","  gpqa: 19072 records\n","  musr: 12096 records\n"]}],"source":["!python extract_openllm_leaderboard_data.py"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15891,"status":"ok","timestamp":1764990949748,"user":{"displayName":"Scott Zhou","userId":"17529720457164178193"},"user_tz":300},"id":"c-ozYzS-miJV","outputId":"4aa63ad0-09c5-4975-b036-7d37f425aa54"},"outputs":[{"output_type":"stream","name":"stdout","text":["Successfully loaded 31168 records\n","\n","Organizing data...\n","\n","Dataset statistics:\n","  gpqa: 545 unique queries\n","  musr: 756 unique queries\n","\n","Extracting queries for each dataset...\n","\n","Dataset statistics:\n","  gpqa:\n","    - Queries: 545\n","    - Models: 16\n","    - Total records: 19072\n","  musr:\n","    - Queries: 756\n","    - Models: 16\n","    - Total records: 12096\n","\n","Saving data to extracted_dataset_samples.jsonl...\n","Successfully saved 31168 records\n","\n","Generating files grouped by dataset...\n","  Saved gpqa dataset to extracted_gpqa_samples.jsonl (19072 records)\n","  Saved musr dataset to extracted_musr_samples.jsonl (12096 records)\n"]}],"source":["!python extract_dataset_samples.py"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":923,"status":"ok","timestamp":1764991064399,"user":{"displayName":"Scott Zhou","userId":"17529720457164178193"},"user_tz":300},"id":"H_5NO4tWm9hG","outputId":"88f92b95-f31e-407c-96c0-1d54ac1f95ca"},"outputs":[{"output_type":"stream","name":"stdout","text":["Calculating query difficulty from extracted_dataset_samples.jsonl\n","================================================================================\n","\n","Reading data and handling duplicates...\n","Found 1301 unique queries\n","\n","Calculating difficulty based on actual answer counts...\n","\n","Checking for duplicates and model counts...\n","  Total records: 31168\n","  Expected records (queries × 16): 20816\n","  WARNING: Found 10352 duplicate records (33.21%)\n","\n","  WARNING: Found 447 queries with issues:\n","    gpqa (gpqa_q0): 16 models, 32 answers (duplicates: 16)\n","    gpqa (gpqa_q1): 16 models, 48 answers (duplicates: 32)\n","    gpqa (gpqa_q2): 16 models, 32 answers (duplicates: 16)\n","    gpqa (gpqa_q3): 16 models, 32 answers (duplicates: 16)\n","    gpqa (gpqa_q4): 16 models, 48 answers (duplicates: 32)\n","    gpqa (gpqa_q5): 16 models, 32 answers (duplicates: 16)\n","    gpqa (gpqa_q6): 16 models, 48 answers (duplicates: 32)\n","    gpqa (gpqa_q7): 16 models, 32 answers (duplicates: 16)\n","    gpqa (gpqa_q8): 16 models, 48 answers (duplicates: 32)\n","    gpqa (gpqa_q9): 16 models, 32 answers (duplicates: 16)\n","    ... and 437 more\n","\n","Grouping by dataset category...\n","  BBH queries: 0\n","  MATH queries: 0\n","  MMLU_PRO queries: 0\n","\n","================================================================================\n","Difficulty Statistics:\n","================================================================================\n","\n","BBH:\n","\n","MATH:\n","\n","MMLU_PRO:\n","Saved to: query_difficulty.jsonl\n","\n","================================================================================\n","Sample: Top 10 Most Difficult Queries (by category):\n","================================================================================\n","\n","================================================================================\n","Done!\n","================================================================================\n"]}],"source":["!python calculate_query_difficulty.py"]},{"cell_type":"code","source":["!python routellm_baseline.py \\\n","--input data/model_data/extracted_dataset_samples_ood.jsonl \\\n","--router bert \\\n","--output-dir data/baseline_scores"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WJg1lx8aWF8U","executionInfo":{"status":"ok","timestamp":1765517962638,"user_tz":300,"elapsed":1541498,"user":{"displayName":"Scott Zhou","userId":"17529720457164178193"}},"outputId":"3b9713bf-325e-45ca-f7af-ece37ecd1aac"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading queries from data/model_data/extracted_dataset_samples_ood.jsonl...\n","Loaded 1301 unique queries\n","================================================================================\n","RouteLLM Baseline Score Generation\n","================================================================================\n","Input file: data/model_data/extracted_dataset_samples_ood.jsonl\n","Output directory: data/baseline_scores\n","Routers to run: bert\n","\n","================================================================================\n","\n","Initializing bert router...\n","config.json: 100% 924/924 [00:00<00:00, 6.57MB/s]\n","2025-12-12 05:13:50.653986: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1765516430.673825    3232 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1765516430.679801    3232 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","W0000 00:00:1765516430.696196    3232 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1765516430.696221    3232 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1765516430.696226    3232 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1765516430.696231    3232 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","2025-12-12 05:13:50.700965: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","model.safetensors: 100% 1.11G/1.11G [00:26<00:00, 42.7MB/s]\n","tokenizer_config.json: 1.15kB [00:00, 3.91MB/s]\n","sentencepiece.bpe.model: 100% 5.07M/5.07M [00:01<00:00, 3.75MB/s]\n","tokenizer.json: 100% 17.1M/17.1M [00:01<00:00, 12.6MB/s]\n","special_tokens_map.json: 100% 280/280 [00:00<00:00, 2.36MB/s]\n","bert router initialized successfully\n","\n","Generating scores with bert router...\n","Processing with bert: 100% 1301/1301 [24:51<00:00,  1.15s/it]\n","Saving 1301 results to data/baseline_scores/bert_router_scores.jsonl...\n","Results saved successfully\n","\n","Score Statistics for bert:\n","  Min:  0.3855\n","  Max:  0.5175\n","  Mean: 0.4568\n","\n","================================================================================\n","Processing complete!\n","================================================================================\n"]}]}],"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","mount_file_id":"1duH-DkDsNsRazAcuD0t5VTgSwydFMGCf","authorship_tag":"ABX9TyPbbVsX+W2/qFHgaB1v8zBe"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}